# í˜•ì‚¬ë²• RAG ì±—ë´‡ í•™ìŠµ ê°€ì´ë“œ

> **ëª©í‘œ**: RAG, Constitutional AI, Few-Shot Learning ë“± ìµœì‹  LLM ê¸°ìˆ ì„ ì‹¤ì œë¡œ êµ¬í˜„í•˜ê³  ì´í•´í•˜ê¸°

## ğŸ“ í•™ìŠµ ëª©í‘œ

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒë“¤:

1. **RAG (Retrieval-Augmented Generation)**
   - ì™œ RAGê°€ í•„ìš”í•œê°€?
   - Fine-tuning vs RAG ë¹„êµ
   - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ë° í™œìš©

2. **ì„ë² ë”© (Embeddings)**
   - í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì´ìœ 
   - í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì„ íƒ ê¸°ì¤€
   - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°

3. **ì²­í‚¹ ì „ëµ (Chunking)**
   - ì™œ ë¬¸ì„œë¥¼ ë‚˜ëˆ„ì–´ì•¼ í•˜ëŠ”ê°€?
   - ìµœì ì˜ chunk size ê²°ì •
   - Overlapì˜ ì—­í• 

4. **Constitutional AI**
   - AIì—ê²Œ ì›ì¹™ì„ ë¶€ì—¬í•˜ëŠ” ë°©ë²•
   - ìê¸° ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜
   - Hallucination ë°©ì§€

5. **Few-Shot Learning**
   - 0-shot vs Few-shot ë¹„êµ
   - ìµœì ì˜ ì˜ˆì‹œ ê°œìˆ˜
   - ì˜ˆì‹œ ì„ íƒ ê¸°ì¤€

6. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**
   - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°
   - ë²•ë¥  AIë¥¼ ìœ„í•œ íŠ¹ìˆ˜ ê³ ë ¤ì‚¬í•­

---

## ğŸ“š í•™ìŠµ ë¡œë“œë§µ

### Phase 1: ê¸°ì´ˆ ì´í•´ (1-2ì£¼)

#### Week 1: RAG ê°œë…ê³¼ ì„ë² ë”©

**ì½ì–´ë³¼ ê²ƒ**:
- `DESIGN_DECISIONS.md` ì„¹ì…˜ 1, 2
- Lewis et al. (2020) - "Retrieval-Augmented Generation" ë…¼ë¬¸

**ì‹¤ìŠµ**:
```python
# 1. ì„ë² ë”© ìƒì„± ì‹¤í—˜
from src.embeddings.embedder import KoreanLegalEmbedder

embedder = KoreanLegalEmbedder()

# ìœ ì‚¬í•œ ë¬¸ì¥ë“¤ ì„ë² ë”©
texts = [
    "ì ˆë„ì£„ëŠ” íƒ€ì¸ì˜ ì¬ë¬¼ì„ ì ˆì·¨í•˜ëŠ” ë²”ì£„ì´ë‹¤",
    "ë„ë‘‘ì§ˆì€ ë‚¨ì˜ ë¬¼ê±´ì„ í›”ì¹˜ëŠ” í–‰ìœ„ì´ë‹¤",
    "ì‚¬ê¸°ì£„ëŠ” ì‚¬ëŒì„ ì†ì—¬ ì¬ë¬¼ì„ ì·¨ë“í•˜ëŠ” ë²”ì£„ì´ë‹¤"
]

embeddings = embedder.embed_documents(texts)

# ìœ ì‚¬ë„ ë¹„êµ
sim_1_2 = embedder.compute_similarity(embeddings[0], embeddings[1])
sim_1_3 = embedder.compute_similarity(embeddings[0], embeddings[2])

print(f"ì ˆë„ì£„ vs ë„ë‘‘ì§ˆ: {sim_1_2:.4f}")  # ë†’ì€ ìœ ì‚¬ë„ (ê°™ì€ ì˜ë¯¸)
print(f"ì ˆë„ì£„ vs ì‚¬ê¸°ì£„: {sim_1_3:.4f}")  # ë‚®ì€ ìœ ì‚¬ë„ (ë‹¤ë¥¸ ë²”ì£„)
```

**ì§ˆë¬¸í•´ë³¼ ê²ƒ**:
1. ì™œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€? (ìœ í´ë¦¬ë“œ ê±°ë¦¬ì™€ ì°¨ì´)
2. ì„ë² ë”© ì°¨ì›ì´ 768ì¸ ì´ìœ ëŠ”?
3. í•œêµ­ì–´ ëª¨ë¸ê³¼ ì˜ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ ì°¨ì´ëŠ”?

#### Week 2: ì²­í‚¹ê³¼ ë²¡í„° DB

**ì½ì–´ë³¼ ê²ƒ**:
- `DESIGN_DECISIONS.md` ì„¹ì…˜ 3, 4
- ChromaDB ê³µì‹ ë¬¸ì„œ

**ì‹¤ìŠµ**:
```python
# ì²­í‚¹ ì‹¤í—˜
from src.data.preprocessor import LawTextPreprocessor

preprocessor = LawTextPreprocessor(chunk_size=500, chunk_overlap=50)

# ê¸´ íŒê²°ë¬¸ ì²­í‚¹
long_text = """
ì œ329ì¡°(ì ˆë„) íƒ€ì¸ì˜ ì¬ë¬¼ì„ ì ˆì·¨í•œ ìëŠ” 6ë…„ ì´í•˜ì˜ ì§•ì—­ ë˜ëŠ”
1ì²œë§Œì› ì´í•˜ì˜ ë²Œê¸ˆì— ì²˜í•œë‹¤.

ì œ330ì¡°(ì•¼ê°„ì£¼ê±°ì¹¨ì…ì ˆë„) ì•¼ê°„ì— ì‚¬ëŒì˜ ì£¼ê±°...
"""

chunks = preprocessor.chunk_text(long_text)

print(f"ì›ë³¸ ê¸¸ì´: {len(long_text)} ì")
print(f"ì²­í¬ ê°œìˆ˜: {len(chunks)}")
for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {len(chunk['text'])} ì")
```

**ì‹¤í—˜ ê³¼ì œ**:
1. chunk_sizeë¥¼ 300, 500, 800ìœ¼ë¡œ ë°”ê¿”ê°€ë©° ê²°ê³¼ ë¹„êµ
2. overlap 0%, 10%, 20% ë¹„êµ
3. ì–´ë–¤ ì„¤ì •ì´ ê²€ìƒ‰ í’ˆì§ˆì´ ì¢‹ì€ì§€ í…ŒìŠ¤íŠ¸

---

### Phase 2: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (2-3ì£¼)

#### Week 3: ë²¡í„° DB êµ¬ì¶•

**ì‹¤ìŠµ**: ì‹¤ì œ ë°ì´í„°ë¡œ ë²¡í„° DB ë§Œë“¤ê¸°

```bash
# í…ŒìŠ¤íŠ¸ìš© (1000ê°œ ë¬¸ì„œ)
python scripts/build_vectordb.py \
    --db_type chroma \
    --max_docs 1000 \
    --test_query "ì ˆë„ì£„ì˜ êµ¬ì„±ìš”ê±´ì€?"

# ì „ì²´ ë°ì´í„° (ì‹œê°„ ì†Œìš”)
python scripts/build_vectordb.py \
    --db_type chroma
```

**ê´€ì°°í•  ê²ƒ**:
1. ì„ë² ë”© ìƒì„± ì‹œê°„ (1000ê°œ vs 10000ê°œ)
2. ë²¡í„° DB í¬ê¸°
3. ê²€ìƒ‰ ì†ë„

**A/B í…ŒìŠ¤íŠ¸**:
```python
# ChromaDB vs FAISS ë¹„êµ
import time

# ChromaDB
start = time.time()
chroma_results = chroma_db.search(query_embedding, top_k=5)
chroma_time = time.time() - start

# FAISS
start = time.time()
faiss_results = faiss_db.search(query_embedding, top_k=5)
faiss_time = time.time() - start

print(f"ChromaDB: {chroma_time:.4f}s")
print(f"FAISS: {faiss_time:.4f}s")
```

#### Week 4-5: RAG ê²€ìƒ‰ ì‹¤í—˜

**ì‹¤ìŠµ**: ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµ ë¹„êµ

```python
from src.retrieval.retriever import LegalDocumentRetriever

retriever = LegalDocumentRetriever(vectordb, embedder, top_k=5)

# 1. ê¸°ë³¸ ê²€ìƒ‰
results_basic = retriever.retrieve("ì ˆë„ì£„ë€?")

# 2. ë‹¤ì–‘ì„± ê³ ë ¤ ê²€ìƒ‰
results_diverse = retriever.get_diverse_results(
    "ì ˆë„ì£„ë€?",
    diversity_threshold=0.85
)

# 3. ìŠ¤ì½”ì–´ í•„í„°ë§
results_filtered = retriever.retrieve_with_scores(
    "ì ˆë„ì£„ë€?",
    score_threshold=0.7
)

# ë¹„êµ ë¶„ì„
print("ê¸°ë³¸ ê²€ìƒ‰:", len(results_basic))
print("ë‹¤ì–‘ì„± ê²€ìƒ‰:", len(results_diverse))
print("í•„í„°ë§ ê²€ìƒ‰:", len(results_filtered))
```

**ì‹¤í—˜ ë©”íŠ¸ë¦­**:
```python
def evaluate_retrieval(query, expected_doc_ids, retrieved_docs):
    """ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€"""
    retrieved_ids = [doc['id'] for doc in retrieved_docs]

    # Precision: ê²€ìƒ‰ëœ ê²ƒ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨
    relevant_retrieved = set(expected_doc_ids) & set(retrieved_ids)
    precision = len(relevant_retrieved) / len(retrieved_ids)

    # Recall: ê´€ë ¨ ë¬¸ì„œ ì¤‘ ê²€ìƒ‰ëœ ë¹„ìœ¨
    recall = len(relevant_retrieved) / len(expected_doc_ids)

    # F1 Score
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return {
        'precision': precision,
        'recall': recall,
        'f1': f1
    }
```

---

### Phase 3: Constitutional AI (2ì£¼)

#### Week 6: Constitutional Principles ì´í•´

**ì½ì–´ë³¼ ê²ƒ**:
- `DESIGN_DECISIONS.md` ì„¹ì…˜ 7
- Anthropic (2022) - "Constitutional AI" ë…¼ë¬¸
- `src/llm/constitutional_prompts.py` ì½”ë“œ

**ì‹¤ìŠµ**: ì›ì¹™ ìœ„ë°˜ ì°¾ê¸°

```python
from src.llm.constitutional_prompts import ConstitutionalPrinciples

# ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ (ì›ì¹™ ìœ„ë°˜)
bad_answer = """
ì ˆë„ì£„ëŠ” ë‚¨ì˜ ë¬¼ê±´ì„ í›”ì¹˜ë©´ ë©ë‹ˆë‹¤.
ì´ˆë²”ì´ë©´ ì§‘í–‰ìœ ì˜ˆ ë°›ì„ ìˆ˜ ìˆì–´ìš”!
"""

# ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ (ì›ì¹™ ì¤€ìˆ˜)
good_answer = """
ì ˆë„ì£„(í˜•ë²• ì œ329ì¡°)ëŠ” "íƒ€ì¸ì˜ ì¬ë¬¼ì„ ì ˆì·¨í•œ ìëŠ”
6ë…„ ì´í•˜ì˜ ì§•ì—­ ë˜ëŠ” 1ì²œë§Œì› ì´í•˜ì˜ ë²Œê¸ˆì— ì²˜í•œë‹¤"ê³ 
ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.

[íŒë¡€: ëŒ€ë²•ì› 2020ë„1234]ì— ë”°ë¥´ë©´...

âš ï¸ ì´ëŠ” ë²•ë¥  ì •ë³´ì´ë©°, ì‹¤ì œ ì‚¬ê±´ì€ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.
"""

# ì–´ë–¤ ì›ì¹™ì„ ìœ„ë°˜/ì¤€ìˆ˜í–ˆëŠ”ì§€ ë¶„ì„í•´ë³´ì„¸ìš”!
```

**ê³¼ì œ**:
1. ê° ì›ì¹™ì´ ì™œ í•„ìš”í•œì§€ ì„¤ëª…í•˜ê¸°
2. ì›ì¹™ ìœ„ë°˜ ì‚¬ë¡€ 5ê°œ ë§Œë“¤ê¸°
3. Constitutional Principles 1ê°œ ì¶”ê°€ ì œì•ˆí•˜ê¸°

#### Week 7: Self-Critique êµ¬í˜„

**ì‹¤ìŠµ**: ìê¸° ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜

```python
from src.llm.constitutional_chatbot import ConstitutionalLawChatbot

# Self-Critique í™œì„±í™”
chatbot = ConstitutionalLawChatbot(
    retriever=retriever,
    llm_client=llm_client,
    enable_self_critique=True,
    critique_threshold=0.5
)

# ë””ë²„ê·¸ ëª¨ë“œë¡œ ê²€ì¦ ê³¼ì • í™•ì¸
response = chatbot.chat(
    "ì ˆë„ì£„ë€?",
    include_critique_log=True
)

print("=== ì´ˆê¸° ë‹µë³€ ===")
print(response['answer'])

print("\n=== ê²€ì¦ ê²°ê³¼ ===")
print(response.get('critique', {}))

print(f"\nìˆ˜ì • ì—¬ë¶€: {response['revised']}")
```

**ì‹¤í—˜**:
```python
# ì‹¤í—˜: Self-Critique íš¨ê³¼ ì¸¡ì •

results_with_critique = []
results_without_critique = []

test_queries = [
    "ì ˆë„ì£„ë€?",
    "ì‚¬ê¸°ì£„ vs íš¡ë ¹ì£„",
    "ì •ë‹¹ë°©ìœ„ ìš”ê±´ì€?"
]

# With Self-Critique
chatbot_with = ConstitutionalLawChatbot(
    retriever, llm_client,
    enable_self_critique=True
)

for query in test_queries:
    response = chatbot_with.chat(query)
    results_with_critique.append(response)

# Without Self-Critique
chatbot_without = ConstitutionalLawChatbot(
    retriever, llm_client,
    enable_self_critique=False
)

for query in test_queries:
    response = chatbot_without.chat(query)
    results_without_critique.append(response)

# ë¹„êµ ë¶„ì„: ì¶œì²˜ ëª…ì‹œìœ¨, ë©´ì±… ì¡°í•­ í¬í•¨ ì—¬ë¶€ ë“±
```

---

### Phase 4: Few-Shot Learning (1ì£¼)

#### Week 8: Few-Shot ì‹¤í—˜

**ì½ì–´ë³¼ ê²ƒ**:
- `DESIGN_DECISIONS.md` ì„¹ì…˜ 6
- `src/llm/constitutional_prompts.py` - FewShotExamples

**ì‹¤ìŠµ**: Shot ìˆ˜ ë¹„êµ

```python
# 0-Shot (ì˜ˆì‹œ ì—†ìŒ)
prompt_0shot = """
ì§ˆë¬¸: ì ˆë„ì£„ë€?

ë‹µë³€:
"""

# 1-Shot
prompt_1shot = """
ì˜ˆì‹œ:
Q: ì‚¬ê¸°ì£„ë€?
A: ì‚¬ê¸°ì£„(í˜•ë²• ì œ347ì¡°)ëŠ”...

ì§ˆë¬¸: ì ˆë„ì£„ë€?

ë‹µë³€:
"""

# 3-Shot (í˜„ì¬ ì„¤ì •)
prompt_3shot = FewShotExamples.format_examples() + """
ì§ˆë¬¸: ì ˆë„ì£„ë€?

ë‹µë³€:
"""

# 5-Shot
prompt_5shot = """
[5ê°œ ì˜ˆì‹œ...]

ì§ˆë¬¸: ì ˆë„ì£„ë€?

ë‹µë³€:
"""

# ê²°ê³¼ ë¹„êµ
# - ë‹µë³€ í’ˆì§ˆ
# - í† í° ì‚¬ìš©ëŸ‰
# - ì‘ë‹µ ì‹œê°„
```

**ì‹¤í—˜ ê²°ê³¼ ë¶„ì„**:
```python
import matplotlib.pyplot as plt

shot_counts = [0, 1, 3, 5]
quality_scores = [3.2, 4.1, 4.7, 4.8]  # ì‚¬ëŒì´ í‰ê°€
token_costs = [100, 300, 700, 1100]  # í† í° ìˆ˜

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

ax1.plot(shot_counts, quality_scores, marker='o')
ax1.set_title('ë‹µë³€ í’ˆì§ˆ vs Shot ìˆ˜')
ax1.set_xlabel('Shot ìˆ˜')
ax1.set_ylabel('í’ˆì§ˆ ì ìˆ˜ (1-5)')

ax2.plot(shot_counts, token_costs, marker='o', color='red')
ax2.set_title('í† í° ë¹„ìš© vs Shot ìˆ˜')
ax2.set_xlabel('Shot ìˆ˜')
ax2.set_ylabel('í† í° ìˆ˜')

plt.tight_layout()
plt.show()

# ê²°ë¡ : 3-shotì´ í’ˆì§ˆê³¼ ë¹„ìš©ì˜ ìµœì ì !
```

---

## ğŸ”¬ ì‹¤í—˜ í”„ë¡œì íŠ¸

### ì‹¤í—˜ 1: ì²­í‚¹ ì „ëµ ìµœì í™”

**ëª©í‘œ**: ìµœì ì˜ chunk_sizeì™€ overlap ì°¾ê¸°

**ë°©ë²•**:
```python
from src.llm.constitutional_chatbot import ExperimentalChatbot

configs = [
    {'chunk_size': 300, 'overlap': 30},
    {'chunk_size': 500, 'overlap': 50},  # í˜„ì¬ ì„¤ì •
    {'chunk_size': 800, 'overlap': 100},
]

test_queries = [
    "ì ˆë„ì£„ êµ¬ì„±ìš”ê±´ì€?",
    "ì •ë‹¹ë°©ìœ„ ìš”ê±´ì€?",
    # ... ë” ë§ì€ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
]

results = {}

for config in configs:
    # ê° ì„¤ì •ìœ¼ë¡œ ë²¡í„° DB ì¬êµ¬ì¶•
    preprocessor = LawTextPreprocessor(**config)
    # ... (ë²¡í„° DB êµ¬ì¶•)

    chatbot = ExperimentalChatbot(retriever, llm_client, config)

    for query in test_queries:
        response = chatbot.chat(query)
        # ê²°ê³¼ ì €ì¥

    results[str(config)] = chatbot.get_experiment_results()

# ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”
```

### ì‹¤í—˜ 2: ì„ë² ë”© ëª¨ë¸ ë¹„êµ

**ëª©í‘œ**: í•œêµ­ì–´ ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ

**ë°©ë²•**:
```python
models = [
    "jhgan/ko-sroberta-multitask",  # í˜„ì¬
    "BM-K/KoSimCSE-roberta",
    "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
]

for model_name in models:
    embedder = KoreanLegalEmbedder(model_name=model_name)
    # ë²¡í„° DB êµ¬ì¶•
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```

### ì‹¤í—˜ 3: Constitutional AI íš¨ê³¼ ì¸¡ì •

**ëª©í‘œ**: Self-Critiqueì˜ ì‹¤ì œ íš¨ê³¼ ê²€ì¦

**í‰ê°€ ê¸°ì¤€**:
1. ì¶œì²˜ ëª…ì‹œìœ¨
2. Hallucination ë°œìƒë¥ 
3. ë‹µë³€ í’ˆì§ˆ (ì‚¬ëŒ í‰ê°€)

```python
def evaluate_constitutional_ai(answers):
    metrics = {
        'cite_rate': 0,  # ì¶œì²˜ ëª…ì‹œ ë¹„ìœ¨
        'hallucination_rate': 0,  # í™˜ê° ë°œìƒ ë¹„ìœ¨
        'disclaimer_rate': 0,  # ë©´ì±… ì¡°í•­ í¬í•¨ ë¹„ìœ¨
        'professional_tone': 0  # ì „ë¬¸ì  ì–´ì¡° (1-5)
    }

    for answer in answers:
        # [ë²•ë ¹:...] ë˜ëŠ” [íŒë¡€:...] í¬í•¨ ì—¬ë¶€
        if '[ë²•ë ¹:' in answer or '[íŒë¡€:' in answer:
            metrics['cite_rate'] += 1

        # âš ï¸ í¬í•¨ ì—¬ë¶€
        if 'âš ï¸' in answer:
            metrics['disclaimer_rate'] += 1

        # ... ë” ë§ì€ ë©”íŠ¸ë¦­

    # ë¹„ìœ¨ ê³„ì‚°
    for key in metrics:
        metrics[key] /= len(answers)

    return metrics
```

---

## ğŸ’¡ í™•ì¥ ì•„ì´ë””ì–´

### 1. Hybrid Search êµ¬í˜„

**RAG ê°œì„ **:
```python
# Semantic Search + BM25 (í‚¤ì›Œë“œ)
from rank_bm25 import BM25Okapi

class HybridRetriever:
    def __init__(self, vectordb, embedder):
        self.semantic_retriever = SemanticRetriever(vectordb, embedder)
        self.bm25 = None  # ì´ˆê¸°í™” í•„ìš”

    def retrieve(self, query, top_k=5, semantic_weight=0.7):
        # Semantic ê²€ìƒ‰
        semantic_results = self.semantic_retriever.retrieve(query, top_k=20)

        # BM25 ê²€ìƒ‰
        bm25_results = self.bm25_search(query, top_k=20)

        # ê°€ì¤‘ í•©ì‚° ë° ì¬ìˆœìœ„í™”
        combined = self.combine_results(
            semantic_results,
            bm25_results,
            semantic_weight
        )

        return combined[:top_k]
```

### 2. ë‹µë³€ í’ˆì§ˆ ìë™ í‰ê°€

**RAGAS (RAG Assessment) í”„ë ˆì„ì›Œí¬**:
```python
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy

# ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œì— ì¶©ì‹¤í•œê°€?
faithfulness_score = faithfulness.score(
    question=query,
    answer=answer,
    contexts=retrieved_docs
)

# ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ê°€?
relevancy_score = answer_relevancy.score(
    question=query,
    answer=answer
)
```

### 3. ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµ

**Chain-of-Thought (CoT)**:
```python
COT_PROMPT = """
ì§ˆë¬¸: {question}

ë‹¨ê³„ì ìœ¼ë¡œ ìƒê°í•´ë´…ì‹œë‹¤:

1ë‹¨ê³„: ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì€ ë¬´ì—‡ì¸ê°€?
2ë‹¨ê³„: ê´€ë ¨ ë²•ë ¹ì€ ë¬´ì—‡ì¸ê°€?
3ë‹¨ê³„: ê´€ë ¨ íŒë¡€ëŠ” ì–´ë–»ê²Œ íŒë‹¨í–ˆëŠ”ê°€?
4ë‹¨ê³„: ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ë©´?

ìµœì¢… ë‹µë³€:
"""
```

**Tree-of-Thought (ToT)**:
```python
# ì—¬ëŸ¬ ì¶”ë¡  ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³  ìµœì„  ì„ íƒ
```

---

## ğŸ“Š í‰ê°€ ë° ê°œì„ 

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            'retrieval': {
                'precision': [],
                'recall': [],
                'mrr': []  # Mean Reciprocal Rank
            },
            'generation': {
                'faithfulness': [],  # ê²€ìƒ‰ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ë¹„ìœ¨
                'cite_rate': [],  # ì¶œì²˜ ëª…ì‹œ ë¹„ìœ¨
                'hallucination_rate': []  # í™˜ê° ë°œìƒ ë¹„ìœ¨
            },
            'user_experience': {
                'response_time': [],
                'satisfaction': []  # ì‚¬ìš©ì ë§Œì¡±ë„ (1-5)
            }
        }

    def log_query(self, query, response, ground_truth=None):
        """ê° ì¿¼ë¦¬ì˜ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        # ... ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì €ì¥

    def generate_report(self):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        # ... í†µê³„ ë¶„ì„ ë° ì‹œê°í™”
```

### ì‚¬ìš©ì í”¼ë“œë°±

```python
# Streamlit UIì— í”¼ë“œë°± ë²„íŠ¼ ì¶”ê°€
if st.button("ğŸ‘ ë„ì›€ì´ ë˜ì—ˆì–´ìš”"):
    collect_feedback(query, answer, rating=5)

if st.button("ğŸ‘ ë³„ë¡œì˜ˆìš”"):
    collect_feedback(query, answer, rating=1)
    reason = st.text_input("ì–´ë–¤ ì ì´ ì•„ì‰¬ì› ë‚˜ìš”?")
```

---

## ğŸ¯ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ì´ˆ

- [ ] RAGê°€ ë¬´ì—‡ì´ê³  ì™œ í•„ìš”í•œì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] ì„ë² ë”©ì´ í…ìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ”ì§€ ì•ˆë‹¤
- [ ] ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤
- [ ] ì²­í‚¹ì˜ ëª©ì ê³¼ ì¤‘ìš”ì„±ì„ ì´í•´í•œë‹¤

### ì¤‘ê¸‰

- [ ] ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì§ì ‘ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤
- [ ] ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµì„ ë¹„êµ ì‹¤í—˜í•  ìˆ˜ ìˆë‹¤
- [ ] Constitutional AIì˜ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] Few-Shot Learningì˜ íš¨ê³¼ë¥¼ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦í•  ìˆ˜ ìˆë‹¤

### ê³ ê¸‰

- [ ] ì—¬ëŸ¬ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆë‹¤
- [ ] ìì‹ ë§Œì˜ Constitutional Principlesë¥¼ ì •ì˜í•  ìˆ˜ ìˆë‹¤
- [ ] A/B í…ŒìŠ¤íŠ¸ë¡œ ì‹œìŠ¤í…œì„ ê°œì„ í•  ìˆ˜ ìˆë‹¤
- [ ] ë‹µë³€ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë‹¤

---

## ğŸ“– ì¶”ì²œ ì½ì„ê±°ë¦¬

### ë…¼ë¬¸
1. Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
2. Anthropic (2022) - "Constitutional AI: Harmlessness from AI Feedback"
3. Brown et al. (2020) - "Language Models are Few-Shot Learners" (GPT-3)

### ë¸”ë¡œê·¸/ì•„í‹°í´
- Anthropic Blog: Constitutional AI
- HuggingFace: Sentence Transformers Guide
- OpenAI Cookbook: Embeddings Guide

### ë„êµ¬ ë¬¸ì„œ
- ChromaDB Documentation
- FAISS Documentation
- LangChain Documentation

---

## ğŸ¤ ì»¤ë®¤ë‹ˆí‹°

**í† ë¡  ì£¼ì œ**:
1. ë²•ë¥  AIì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ì •í™•ì„±ì¸ê°€, ì„¤ëª…ê°€ëŠ¥ì„±ì¸ê°€?
2. Constitutional AIì˜ í•œê³„ëŠ” ë¬´ì—‡ì¸ê°€?
3. Few-Shot Learningì˜ ìµœì  ì˜ˆì‹œ ê°œìˆ˜ëŠ” ë„ë©”ì¸ë§ˆë‹¤ ë‹¤ë¥¸ê°€?
4. RAG vs Fine-tuning, ì–¸ì œ ë¬´ì—‡ì„ ì„ íƒí•´ì•¼ í•˜ëŠ”ê°€?

**ê¸°ì—¬ ë°©ë²•**:
1. ìƒˆë¡œìš´ Few-Shot ì˜ˆì‹œ ì¶”ê°€
2. Constitutional Principles ê°œì„ 
3. í‰ê°€ ë©”íŠ¸ë¦­ ì œì•ˆ
4. ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ìˆ˜ì •

---

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë„˜ì–´,
**ì™œ ì´ëŸ° ê¸°ìˆ ì„ ì‚¬ìš©í•˜ëŠ”ì§€, ì–´ë–¤ ìƒí™©ì—ì„œ íš¨ê³¼ì ì¸ì§€**ë¥¼
ê¹Šì´ ì´í•´í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤!

Happy Learning! ğŸš€
