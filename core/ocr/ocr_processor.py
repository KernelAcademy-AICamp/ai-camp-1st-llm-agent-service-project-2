"""
ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ í†µí•œ OCR í’ˆì§ˆ ê°œì„ 
ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ OCR ì •í™•ë„ í–¥ìƒ
"""

import fitz  # PyMuPDF
from pathlib import Path
import json
from datetime import datetime
import logging
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import numpy as np
import cv2
import io
import unicodedata

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DocumentQualityAssessor:
    """ë¬¸ì„œ í’ˆì§ˆ í‰ê°€ í´ë˜ìŠ¤"""

    @staticmethod
    def assess_sharpness(image):
        """
        ì„ ëª…ë„ í‰ê°€ (Laplacian ë¶„ì‚°)
        ë†’ì„ìˆ˜ë¡ ì„ ëª…í•¨ (>100: ì„ ëª…, 50-100: ë³´í†µ, <50: íë¦¼)
        """
        if isinstance(image, Image.Image):
            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        elif len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()
        return laplacian_var

    @staticmethod
    def assess_noise(image):
        """
        ë…¸ì´ì¦ˆ ìˆ˜ì¤€ í‰ê°€ (í‘œì¤€í¸ì°¨ ë¶„ì„)
        ë†’ì„ìˆ˜ë¡ ë…¸ì´ì¦ˆê°€ ë§ìŒ (>50: ë§ìŒ, 20-50: ë³´í†µ, <20: ì ìŒ)
        """
        if isinstance(image, Image.Image):
            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        elif len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # ë¡œì»¬ í‘œì¤€í¸ì°¨ë¡œ ë…¸ì´ì¦ˆ ì¶”ì •
        kernel_size = 5
        local_mean = cv2.blur(image.astype(float), (kernel_size, kernel_size))
        local_sq_mean = cv2.blur((image.astype(float) ** 2), (kernel_size, kernel_size))
        local_variance = local_sq_mean - (local_mean ** 2)
        noise_level = np.mean(np.sqrt(local_variance))

        return noise_level

    @staticmethod
    def assess_contrast(image):
        """
        ëŒ€ë¹„ í‰ê°€ (íˆìŠ¤í† ê·¸ë¨ ë¶„ì„)
        ë†’ì„ìˆ˜ë¡ ëŒ€ë¹„ê°€ ì¢‹ìŒ (>80: ì¢‹ìŒ, 40-80: ë³´í†µ, <40: ë‚®ìŒ)
        """
        if isinstance(image, Image.Image):
            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        elif len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # RMS contrast (Root Mean Square)
        rms_contrast = np.std(image)
        return rms_contrast

    @staticmethod
    def assess_brightness(image):
        """
        ë°ê¸° í‰ê°€ (í‰ê·  í”½ì…€ ê°’)
        0-255 ë²”ìœ„ (100-180: ì ì •, >180: ë°ìŒ, <100: ì–´ë‘ì›€)
        """
        if isinstance(image, Image.Image):
            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        elif len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        brightness = np.mean(image)
        return brightness

    @staticmethod
    def assess_resolution(image):
        """
        í•´ìƒë„ í‰ê°€ (ì´ë¯¸ì§€ í¬ê¸°)
        í”½ì…€ ìˆ˜ë¡œ í‰ê°€ (>1M: ê³ í•´ìƒë„, 0.5M-1M: ë³´í†µ, <0.5M: ì €í•´ìƒë„)
        """
        if isinstance(image, Image.Image):
            width, height = image.size
        else:
            height, width = image.shape[:2]

        total_pixels = width * height
        return total_pixels / 1_000_000  # ë©”ê°€í”½ì…€ ë‹¨ìœ„

    @staticmethod
    def assess_quality(image):
        """
        ì¢…í•© í’ˆì§ˆ í‰ê°€ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
        Returns: dict with quality scores and recommended preprocessing
        """
        sharpness = DocumentQualityAssessor.assess_sharpness(image)
        noise = DocumentQualityAssessor.assess_noise(image)
        contrast = DocumentQualityAssessor.assess_contrast(image)
        brightness = DocumentQualityAssessor.assess_brightness(image)
        resolution = DocumentQualityAssessor.assess_resolution(image)

        # ì›ë³¸ ì ìˆ˜
        scores = {
            'sharpness': sharpness,
            'noise': noise,
            'contrast': contrast,
            'brightness': brightness,
            'resolution_mp': resolution
        }

        # ê° í•­ëª©ì„ 0-100 ì ìˆ˜ë¡œ ì •ê·œí™”
        normalized = {
            'sharpness': min(100, sharpness / 2),  # 200 = 100ì 
            'noise': max(0, 100 - noise * 2),      # 0 = 100ì , 50+ = 0ì 
            'contrast': min(100, contrast * 1.25), # 80 = 100ì 
            'brightness': 100 if 100 < brightness < 180 else max(0, 100 - abs(brightness - 140) / 2),
            'resolution': min(100, resolution * 50)  # 2MP = 100ì 
        }

        # ê°€ì¤‘ì¹˜ ì ìš© (ì¤‘ìš”ë„ì— ë”°ë¼)
        weights = {
            'sharpness': 0.30,    # ì„ ëª…ë„ ê°€ì¥ ì¤‘ìš”
            'contrast': 0.25,     # ëŒ€ë¹„ ì¤‘ìš”
            'noise': 0.20,        # ë…¸ì´ì¦ˆ ì¤‘ê°„
            'resolution': 0.15,   # í•´ìƒë„ ì¤‘ê°„
            'brightness': 0.10    # ë°ê¸° ëœ ì¤‘ìš”
        }

        # ì´ì  ê³„ì‚°
        total_score = sum(normalized[k] * weights[k] for k in weights)

        # í’ˆì§ˆ ë“±ê¸‰ ë° ì „ì²˜ë¦¬ ì „ëµ ê²°ì •
        if total_score >= 80:
            quality_level = 'excellent'
            recommended_preset = 'minimal'
        elif total_score >= 60:
            quality_level = 'good'
            recommended_preset = 'selective'
        else:
            quality_level = 'poor'
            recommended_preset = 'selective'

        # ì „ì²˜ë¦¬ í•„ìš”ë„ íŒë‹¨ (ê°œë³„)
        needs_sharpening = sharpness < 100
        needs_denoising = noise > 30
        needs_contrast_boost = contrast < 50
        needs_brightness_adjustment = brightness < 100 or brightness > 200
        is_low_resolution = resolution < 1.0

        return {
            'scores': scores,
            'normalized_scores': normalized,
            'total_score': total_score,
            'quality_level': quality_level,
            'recommended_preset': recommended_preset,
            'analysis': {
                'needs_sharpening': bool(needs_sharpening),
                'needs_denoising': bool(needs_denoising),
                'needs_contrast_boost': bool(needs_contrast_boost),
                'needs_brightness_adjustment': bool(needs_brightness_adjustment),
                'is_low_resolution': bool(is_low_resolution),
                'contrast_factor': 2.0 if contrast < 30 else 1.5 if contrast < 50 else 1.2,
                'brightness_adjustment': -0.3 if brightness > 200 else 0.3 if brightness < 100 else 0
            }
        }


class ImagePreprocessor:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    @staticmethod
    def pil_to_cv2(pil_image):
        """PIL Imageë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

    @staticmethod
    def cv2_to_pil(cv2_image):
        """OpenCV ì´ë¯¸ì§€ë¥¼ PIL í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return Image.fromarray(cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB))

    @staticmethod
    def grayscale(image):
        """ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ - ìƒ‰ìƒ ì •ë³´ ì œê±°ë¡œ í…ìŠ¤íŠ¸ ê°•ì¡°"""
        if isinstance(image, Image.Image):
            return image.convert('L')
        else:
            return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    @staticmethod
    def increase_contrast(image, factor=2.0):
        """ëŒ€ë¹„ ì¦ê°€ - í…ìŠ¤íŠ¸ì™€ ë°°ê²½ì˜ êµ¬ë¶„ ëª…í™•í™”"""
        if isinstance(image, Image.Image):
            enhancer = ImageEnhance.Contrast(image)
            return enhancer.enhance(factor)
        else:
            # OpenCV: CLAHE (Contrast Limited Adaptive Histogram Equalization)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            return clahe.apply(image)

    @staticmethod
    def sharpen(image):
        """ì„ ëª…ë„ ì¦ê°€ - íë¦¿í•œ í…ìŠ¤íŠ¸ ê°œì„ """
        if isinstance(image, Image.Image):
            return image.filter(ImageFilter.SHARPEN)
        else:
            kernel = np.array([[-1, -1, -1],
                             [-1,  9, -1],
                             [-1, -1, -1]])
            return cv2.filter2D(image, -1, kernel)

    @staticmethod
    def denoise(image):
        """ë…¸ì´ì¦ˆ ì œê±° - ì–¼ë£©, ì  ì œê±°"""
        if isinstance(image, Image.Image):
            # PILì€ ê°„ë‹¨í•œ í•„í„°ë§Œ ì œê³µ
            return image.filter(ImageFilter.MedianFilter(size=3))
        else:
            # OpenCV: Non-local Means Denoising
            return cv2.fastNlMeansDenoising(image, None, 10, 7, 21)

    @staticmethod
    def binarization(image, method='otsu'):
        """ì´ì§„í™” - í‘ë°±ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„"""
        if isinstance(image, Image.Image):
            image = ImagePreprocessor.pil_to_cv2(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        if method == 'otsu':
            # Otsu's ìë™ ì„ê³„ê°’
            _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        elif method == 'adaptive':
            # ì ì‘í˜• ì„ê³„ê°’ (êµ­ì†Œ ì˜ì—­ë³„ ì„ê³„ê°’)
            binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                          cv2.THRESH_BINARY, 11, 2)
        else:
            # ê³ ì • ì„ê³„ê°’
            _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

        return ImagePreprocessor.cv2_to_pil(binary)

    @staticmethod
    def remove_shadows(image):
        """ê·¸ë¦¼ì ì œê±° - ìŠ¤ìº” ë¬¸ì„œì˜ ê·¸ë¦¼ì ì˜í–¥ ê°ì†Œ"""
        if isinstance(image, Image.Image):
            image = ImagePreprocessor.pil_to_cv2(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Morphological operationsìœ¼ë¡œ ë°°ê²½ ì¶”ì •
        dilated = cv2.dilate(image, np.ones((7, 7), np.uint8))
        bg = cv2.medianBlur(dilated, 21)

        # ë°°ê²½ì„ ë¹¼ì„œ ê·¸ë¦¼ì ì œê±°
        diff = 255 - cv2.absdiff(image, bg)

        # ì •ê·œí™”
        norm = cv2.normalize(diff, None, alpha=0, beta=255,
                            norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)

        return ImagePreprocessor.cv2_to_pil(norm)

    @staticmethod
    def deskew(image):
        """ê¸°ìš¸ê¸° ë³´ì • - ìŠ¤ìº” ì‹œ ê¸°ìš¸ì–´ì§„ ë¬¸ì„œ ë³´ì •"""
        if isinstance(image, Image.Image):
            image = ImagePreprocessor.pil_to_cv2(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # í…ìŠ¤íŠ¸ ê°ì§€
        coords = np.column_stack(np.where(image > 0))

        if len(coords) == 0:
            return ImagePreprocessor.cv2_to_pil(image)

        # ìµœì†Œ ì˜ì—­ ì‚¬ê°í˜•ìœ¼ë¡œ ê°ë„ ê³„ì‚°
        angle = cv2.minAreaRect(coords)[-1]

        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle

        # íšŒì „
        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(image, M, (w, h),
                                flags=cv2.INTER_CUBIC,
                                borderMode=cv2.BORDER_REPLICATE)

        return ImagePreprocessor.cv2_to_pil(rotated)

    @staticmethod
    def upscale(image, scale=2):
        """í•´ìƒë„ ì¦ê°€ - ì‘ì€ í…ìŠ¤íŠ¸ ê°œì„ """
        if isinstance(image, Image.Image):
            new_size = (image.width * scale, image.height * scale)
            return image.resize(new_size, Image.Resampling.LANCZOS)
        else:
            return cv2.resize(image, None, fx=scale, fy=scale,
                            interpolation=cv2.INTER_CUBIC)

    @staticmethod
    def morphology_operations(image):
        """í˜•íƒœí•™ì  ì—°ì‚° - í…ìŠ¤íŠ¸ êµ¬ì¡° ê°œì„ """
        if isinstance(image, Image.Image):
            image = ImagePreprocessor.pil_to_cv2(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # ì‘ì€ êµ¬ë© ì±„ìš°ê¸°
        kernel = np.ones((2, 2), np.uint8)
        closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)

        # ì‘ì€ ì  ì œê±°
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)

        return ImagePreprocessor.cv2_to_pil(opened)

    @staticmethod
    def adjust_brightness(image, factor=0.0):
        """
        ë°ê¸° ì¡°ì •
        factor: -1.0 ~ 1.0 (ìŒìˆ˜=ì–´ë‘¡ê²Œ, ì–‘ìˆ˜=ë°ê²Œ)
        """
        if isinstance(image, Image.Image):
            enhancer = ImageEnhance.Brightness(image)
            return enhancer.enhance(1.0 + factor)
        else:
            # OpenCV: ë°ê¸° ì¡°ì •
            adjusted = cv2.convertScaleAbs(image, alpha=1.0, beta=int(255 * factor))
            return adjusted


def pdf_page_to_image(page, dpi=300):
    """PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ê¸°ë³¸)"""
    mat = fitz.Matrix(dpi/72, dpi/72)
    pix = page.get_pixmap(matrix=mat, alpha=False)
    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
    return img


def preprocess_image_selective(image, quality_analysis):
    """
    í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì„ íƒì  ì „ì²˜ë¦¬
    í•„ìš”í•œ ì²˜ë¦¬ë§Œ ì ìš©í•˜ì—¬ ìµœì í™”
    """
    preprocessor = ImagePreprocessor()
    analysis = quality_analysis['analysis']
    steps = []

    # í•­ìƒ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    image = preprocessor.grayscale(image)
    steps.append("ê·¸ë ˆì´ìŠ¤ì¼€ì¼")

    # ì €í•´ìƒë„ì¸ ê²½ìš° í•´ìƒë„ ì¦ê°€
    if analysis['is_low_resolution']:
        image = preprocessor.upscale(image, scale=2)
        steps.append("í•´ìƒë„ ì¦ê°€(2ë°°)")

    # ë…¸ì´ì¦ˆ ì œê±° (í•„ìš”í•œ ê²½ìš°)
    if analysis['needs_denoising']:
        image = preprocessor.denoise(image)
        steps.append("ë…¸ì´ì¦ˆ ì œê±°")

    # ë°ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
    if analysis['needs_brightness_adjustment']:
        factor = analysis['brightness_adjustment']
        image = preprocessor.adjust_brightness(image, factor=factor)
        steps.append(f"ë°ê¸° ì¡°ì •({factor:+.1f})")

    # ëŒ€ë¹„ ì¦ê°€ (í•„ìš”í•œ ê²½ìš°)
    if analysis['needs_contrast_boost']:
        factor = analysis['contrast_factor']
        image = preprocessor.increase_contrast(image, factor=factor)
        steps.append(f"ëŒ€ë¹„ ì¦ê°€({factor}ë°°)")

    # ì„ ëª…ë„ ê°œì„  (í•„ìš”í•œ ê²½ìš°)
    if analysis['needs_sharpening']:
        image = preprocessor.sharpen(image)
        steps.append("ì„ ëª…ë„")

    # í’ˆì§ˆì´ ë‚˜ìœ ê²½ìš°ì—ë§Œ ì´ì§„í™”
    quality_level = quality_analysis['quality_level']
    if quality_level == 'poor':
        image = preprocessor.binarization(image, method='adaptive')
        steps.append("ì´ì§„í™”(ì ì‘í˜•)")
    elif analysis['needs_contrast_boost']:
        # ëŒ€ë¹„ê°€ ì•½ê°„ ë‚®ì€ ê²½ìš° Otsu ì´ì§„í™”
        image = preprocessor.binarization(image, method='otsu')
        steps.append("ì´ì§„í™”(Otsu)")

    logger.info(f"    ì „ì²˜ë¦¬: {' â†’ '.join(steps)}")
    return image


def preprocess_image_pipeline(image, preset='standard'):
    """
    ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ë ˆê±°ì‹œ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)

    Presets:
    - 'standard': í‘œì¤€ ì „ì²˜ë¦¬ (ëŒ€ë¶€ë¶„ì˜ ê²½ìš°)
    - 'aggressive': ê°•ë ¥í•œ ì „ì²˜ë¦¬ (í’ˆì§ˆì´ ë‚˜ìœ ê²½ìš°)
    - 'light': ê°€ë²¼ìš´ ì „ì²˜ë¦¬ (í’ˆì§ˆì´ ì¢‹ì€ ê²½ìš°)
    - 'custom': ëª¨ë“  ì „ì²˜ë¦¬ ì ìš©
    """
    preprocessor = ImagePreprocessor()

    if preset == 'standard':
        # í‘œì¤€: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ëŒ€ë¹„ ì¦ê°€ â†’ ì„ ëª…ë„ â†’ ì´ì§„í™”
        logger.info("    ì „ì²˜ë¦¬: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ëŒ€ë¹„ ì¦ê°€ â†’ ì„ ëª…ë„ â†’ ì´ì§„í™”")
        image = preprocessor.grayscale(image)
        image = preprocessor.denoise(image)
        image = preprocessor.increase_contrast(image, factor=1.5)
        image = preprocessor.sharpen(image)
        image = preprocessor.binarization(image, method='otsu')

    elif preset == 'aggressive':
        # ê°•ë ¥: í•´ìƒë„ ì¦ê°€ â†’ ê·¸ë¦¼ì ì œê±° â†’ ê¸°ìš¸ê¸° ë³´ì • â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ëŒ€ë¹„ â†’ ì´ì§„í™”
        logger.info("    ì „ì²˜ë¦¬: í•´ìƒë„ ì¦ê°€ â†’ ê·¸ë¦¼ì ì œê±° â†’ ê¸°ìš¸ê¸° ë³´ì • â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ëŒ€ë¹„ â†’ ì´ì§„í™”")
        image = preprocessor.upscale(image, scale=2)
        image = preprocessor.remove_shadows(image)
        image = preprocessor.deskew(image)
        image = preprocessor.denoise(image)
        image = preprocessor.increase_contrast(image, factor=2.0)
        image = preprocessor.binarization(image, method='adaptive')

    elif preset == 'light':
        # ê°€ë²¼ìš´: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ â†’ ëŒ€ë¹„ ì¦ê°€ â†’ ì„ ëª…ë„
        logger.info("    ì „ì²˜ë¦¬: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ â†’ ëŒ€ë¹„ ì¦ê°€ â†’ ì„ ëª…ë„")
        image = preprocessor.grayscale(image)
        image = preprocessor.increase_contrast(image, factor=1.2)
        image = preprocessor.sharpen(image)

    elif preset == 'custom':
        # ëª¨ë“  ì „ì²˜ë¦¬ ì ìš© (ì‹¤í—˜ìš©)
        logger.info("    ì „ì²˜ë¦¬: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì ìš©")
        image = preprocessor.upscale(image, scale=2)
        image = preprocessor.grayscale(image)
        image = preprocessor.remove_shadows(image)
        image = preprocessor.deskew(image)
        image = preprocessor.denoise(image)
        image = preprocessor.increase_contrast(image, factor=1.8)
        image = preprocessor.sharpen(image)
        image = preprocessor.morphology_operations(image)
        image = preprocessor.binarization(image, method='adaptive')

    return image


def ocr_image_with_preprocessing(image, lang='kor+eng', preset='standard', quality_analysis=None):
    """ì „ì²˜ë¦¬ í›„ OCR ìˆ˜í–‰"""
    # ì„ íƒì  ì „ì²˜ë¦¬ (í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´)
    if quality_analysis and preset in ['selective', 'minimal']:
        processed_image = preprocess_image_selective(image, quality_analysis)
    else:
        # ë ˆê±°ì‹œ ì „ì²˜ë¦¬ (preset ì‚¬ìš©)
        processed_image = preprocess_image_pipeline(image, preset=preset)

    # OCR ì‹¤í–‰
    custom_config = r'--oem 3 --psm 6'
    text = pytesseract.image_to_string(processed_image, lang=lang, config=custom_config)

    # ì‹ ë¢°ë„ ê³„ì‚°
    data = pytesseract.image_to_data(processed_image, lang=lang,
                                     config=custom_config, output_type=pytesseract.Output.DICT)

    confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0

    return {
        'text': text,
        'confidence': avg_confidence,
        'word_count': len([w for w in data['text'] if w.strip()])
    }


def extract_pdf_with_preprocessing(pdf_path: Path, dpi=300, preset='standard', adaptive=False):
    """
    PDFì—ì„œ ì „ì²˜ë¦¬ + OCR ì¶”ì¶œ

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        dpi: í•´ìƒë„
        preset: ì „ì²˜ë¦¬ ëª¨ë“œ ('light', 'standard', 'aggressive')
        adaptive: Trueì´ë©´ í˜ì´ì§€ë³„ í’ˆì§ˆ í‰ê°€ í›„ ìë™ ì„ íƒ
    """
    logger.info(f"ì²˜ë¦¬ ì¤‘: {pdf_path.name}")

    if adaptive:
        logger.info(f"  ì „ì²˜ë¦¬ ëª¨ë“œ: ì ì‘í˜• (í˜ì´ì§€ë³„ ìë™ ì„ íƒ)")
    else:
        logger.info(f"  ì „ì²˜ë¦¬ ëª¨ë“œ: {preset} (ê³ ì •)")

    doc = fitz.open(pdf_path)

    pages = []
    total_chars = 0
    total_confidence = 0
    preset_usage = {}

    for page_num in range(len(doc)):
        page = doc[page_num]

        logger.info(f"  â†’ Page {page_num + 1}/{len(doc)} ì²˜ë¦¬ ì¤‘...")

        # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
        image = pdf_page_to_image(page, dpi=dpi)

        # ì ì‘í˜• ëª¨ë“œ: í’ˆì§ˆ í‰ê°€ í›„ preset ì„ íƒ
        if adaptive:
            quality_assessment = DocumentQualityAssessor.assess_quality(image)
            selected_preset = quality_assessment['recommended_preset']

            logger.info(f"     í’ˆì§ˆ í‰ê°€: {quality_assessment['quality_level'].upper()} (ì¢…í•©ì ìˆ˜: {quality_assessment['total_score']:.1f}/100)")
            logger.info(f"       - ì„ ëª…ë„: {quality_assessment['scores']['sharpness']:.1f} ({quality_assessment['normalized_scores']['sharpness']:.0f}ì )")
            logger.info(f"       - ë…¸ì´ì¦ˆ: {quality_assessment['scores']['noise']:.1f} ({quality_assessment['normalized_scores']['noise']:.0f}ì )")
            logger.info(f"       - ëŒ€ë¹„: {quality_assessment['scores']['contrast']:.1f} ({quality_assessment['normalized_scores']['contrast']:.0f}ì )")
            logger.info(f"       - ë°ê¸°: {quality_assessment['scores']['brightness']:.1f} ({quality_assessment['normalized_scores']['brightness']:.0f}ì )")
            logger.info(f"       - í•´ìƒë„: {quality_assessment['scores']['resolution_mp']:.2f}MP ({quality_assessment['normalized_scores']['resolution']:.0f}ì )")
            logger.info(f"     â†’ ì „ì²˜ë¦¬ ì „ëµ: {selected_preset.upper()}")

            # í•„ìš”í•œ ì „ì²˜ë¦¬ í•­ëª© ì¶œë ¥
            analysis = quality_assessment['analysis']
            needs = []
            if analysis['needs_sharpening']:
                needs.append("ì„ ëª…ë„")
            if analysis['needs_denoising']:
                needs.append("ë…¸ì´ì¦ˆì œê±°")
            if analysis['needs_contrast_boost']:
                needs.append(f"ëŒ€ë¹„ì¦ê°€({analysis['contrast_factor']}ë°°)")
            if analysis['needs_brightness_adjustment']:
                needs.append(f"ë°ê¸°ì¡°ì •({analysis['brightness_adjustment']:+.1f})")
            if analysis['is_low_resolution']:
                needs.append("í•´ìƒë„ì¦ê°€")

            logger.info(f"     â†’ í•„ìš”í•œ ì²˜ë¦¬: {', '.join(needs) if needs else 'ì—†ìŒ'}")

            preset_usage[selected_preset] = preset_usage.get(selected_preset, 0) + 1
        else:
            selected_preset = preset
            quality_assessment = None

        # ì „ì²˜ë¦¬ + OCR
        ocr_result = ocr_image_with_preprocessing(image, lang='kor+eng', preset=selected_preset, quality_analysis=quality_assessment)

        char_count = len(ocr_result['text'])
        confidence = ocr_result['confidence']

        page_data = {
            'page_number': page_num + 1,
            'text': ocr_result['text'],
            'char_count': char_count,
            'confidence': confidence,
            'word_count': ocr_result['word_count'],
            'preprocessing_used': selected_preset
        }

        if adaptive and quality_assessment:
            page_data['quality_assessment'] = quality_assessment

        pages.append(page_data)

        total_chars += char_count
        total_confidence += confidence

        logger.info(f"     ê¸€ì ìˆ˜: {char_count}ì, ì‹ ë¢°ë„: {confidence:.1f}%")

    doc.close()

    avg_confidence = total_confidence / len(pages) if pages else 0

    result = {
        'filename': pdf_path.name,
        'page_count': len(pages),
        'dpi': dpi,
        'preprocessing': preset if not adaptive else 'adaptive',
        'adaptive_mode': adaptive,
        'total_chars': total_chars,
        'avg_confidence': avg_confidence,
        'pages': pages
    }

    if adaptive:
        result['preset_usage'] = preset_usage

    logger.info(f"  ì™„ë£Œ: ì´ {total_chars:,}ì, í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1f}%")

    if adaptive and preset_usage:
        logger.info(f"  ì „ì²˜ë¦¬ ì‚¬ìš© í†µê³„: {preset_usage}")

    return result


def compare_preprocessing_methods(pdf_path: Path, dpi=300):
    """ì—¬ëŸ¬ ì „ì²˜ë¦¬ ë°©ë²• ë¹„êµ"""
    logger.info(f"\n{'='*70}")
    logger.info(f"ì „ì²˜ë¦¬ ë°©ë²• ë¹„êµ: {pdf_path.name}")
    logger.info('='*70)

    presets = ['light', 'standard', 'aggressive']
    results = []

    for preset in presets:
        logger.info(f"\n[{preset.upper()}] ì „ì²˜ë¦¬ ì ìš© ì¤‘...")
        result = extract_pdf_with_preprocessing(pdf_path, dpi=dpi, preset=preset)
        results.append(result)

    # ë¹„êµ ê²°ê³¼
    logger.info(f"\n{'='*70}")
    logger.info("ì „ì²˜ë¦¬ ë°©ë²• ë¹„êµ ê²°ê³¼")
    logger.info('='*70)

    for result in results:
        logger.info(f"\n[{result['preprocessing'].upper()}]")
        logger.info(f"  ì´ ê¸€ì ìˆ˜: {result['total_chars']:,}ì")
        logger.info(f"  í‰ê·  ì‹ ë¢°ë„: {result['avg_confidence']:.1f}%")

    return results


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    pdf_dir = Path("raw_pdf_data")

    # ì´ë¯¸ì§€ ê¸°ë°˜ PDF íŒŒì¼ ì°¾ê¸°
    all_pdfs = list(pdf_dir.glob("*.pdf"))
    pdf_files = []

    for pdf_file in all_pdfs:
        normalized_name = unicodedata.normalize('NFC', pdf_file.name)
        if 'ë³€í™˜' in normalized_name or 'converted' in normalized_name:
            pdf_files.append(pdf_file)

    if not pdf_files:
        logger.error("ì´ë¯¸ì§€ ê¸°ë°˜ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info("="*70)
    logger.info("ì „ì²˜ë¦¬ ê¸°ë°˜ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    logger.info("="*70)
    logger.info(f"ì´ {len(pdf_files)}ê°œ íŒŒì¼")
    logger.info("")

    # ì ì‘í˜• ì „ì²˜ë¦¬ ì‚¬ìš©
    use_adaptive = True  # True: í’ˆì§ˆ ê¸°ë°˜ ìë™ ì„ íƒ, False: ê³ ì • preset
    preset = 'standard'  # adaptive=Falseì¼ ë•Œ ì‚¬ìš©

    if use_adaptive:
        logger.info(f"ì „ì²˜ë¦¬ ëª¨ë“œ: ì ì‘í˜• (ìë™ í’ˆì§ˆ í‰ê°€)")
    else:
        logger.info(f"ì „ì²˜ë¦¬ ëª¨ë“œ: {preset} (ê³ ì •)")

    logger.info(f"OCR ì—”ì§„: Tesseract")
    logger.info(f"ì–¸ì–´: í•œê¸€ + ì˜ì–´ (kor+eng)")
    logger.info(f"í•´ìƒë„: 300 DPI")
    logger.info("="*70)
    logger.info("")

    # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
    all_results = []

    for idx, pdf_file in enumerate(pdf_files, 1):
        logger.info(f"\n[{idx}/{len(pdf_files)}] {pdf_file.name}")
        result = extract_pdf_with_preprocessing(pdf_file, dpi=300, preset=preset, adaptive=use_adaptive)
        all_results.append(result)

    # ê²°ê³¼ ì €ì¥
    output_dir = Path("extracted_pdf_data")
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    mode_str = 'adaptive' if use_adaptive else preset

    # JSON ì €ì¥
    json_file = output_dir / f"ocr_preprocessed_{mode_str}_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            "ì¶”ì¶œì‹œê°": datetime.now().isoformat(),
            "íŒŒì¼ìˆ˜": len(all_results),
            "OCRì—”ì§„": "Tesseract",
            "ì–¸ì–´": "kor+eng",
            "DPI": 300,
            "ì „ì²˜ë¦¬ëª¨ë“œ": "ì ì‘í˜•" if use_adaptive else preset,
            "ë¬¸ì„œ": all_results
        }, f, ensure_ascii=False, indent=2)

    logger.info(f"\nâœ… JSON ì €ì¥: {json_file}")

    # ê°œë³„ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
    for result in all_results:
        txt_filename = result['filename'].replace('.pdf', f'_preprocessed_{mode_str}.txt')
        txt_file = output_dir / txt_filename

        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"íŒŒì¼: {result['filename']}\n")
            f.write(f"í˜ì´ì§€ ìˆ˜: {result['page_count']}\n")
            f.write(f"ì „ì²˜ë¦¬: {result['preprocessing']}\n")

            if result.get('adaptive_mode'):
                f.write(f"ì „ì²˜ë¦¬ ì‚¬ìš© í†µê³„: {result.get('preset_usage', {})}\n")

            f.write(f"OCR ì–¸ì–´: kor+eng\n")
            f.write(f"í•´ìƒë„: {result['dpi']} DPI\n")
            f.write(f"í‰ê·  ì‹ ë¢°ë„: {result['avg_confidence']:.1f}%\n")
            f.write("="*70 + "\n\n")

            for page in result['pages']:
                preset_used = page.get('preprocessing_used', 'unknown')
                f.write(f"[Page {page['page_number']}] (ì „ì²˜ë¦¬: {preset_used}, ì‹ ë¢°ë„: {page['confidence']:.1f}%)\n")

                if page.get('quality_assessment'):
                    qa = page['quality_assessment']
                    f.write(f"  í’ˆì§ˆ: {qa['quality_level']} (ì„ ëª…ë„: {qa['scores']['sharpness']:.1f}, "
                           f"ë…¸ì´ì¦ˆ: {qa['scores']['noise']:.1f}, ëŒ€ë¹„: {qa['scores']['contrast']:.1f})\n")

                f.write("\n")
                f.write(page['text'])
                f.write("\n" + "-"*70 + "\n\n")

        logger.info(f"âœ… ê°œë³„ íŒŒì¼ ì €ì¥: {txt_file}")

    # ìš”ì•½ í†µê³„
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ìµœì¢… ìš”ì•½")
    logger.info("="*70)
    logger.info(f"ì²˜ë¦¬ëœ íŒŒì¼: {len(all_results)}ê°œ")
    logger.info(f"ì´ í˜ì´ì§€: {sum(r['page_count'] for r in all_results)}í˜ì´ì§€")
    logger.info(f"ì´ ê¸€ì ìˆ˜: {sum(r['total_chars'] for r in all_results):,}ì")
    logger.info(f"í‰ê·  ì‹ ë¢°ë„: {sum(r['avg_confidence'] for r in all_results) / len(all_results):.1f}%")

    if use_adaptive:
        # ì „ì²´ preset ì‚¬ìš© í†µê³„
        total_preset_usage = {}
        for result in all_results:
            if result.get('preset_usage'):
                for preset_name, count in result['preset_usage'].items():
                    total_preset_usage[preset_name] = total_preset_usage.get(preset_name, 0) + count

        logger.info("")
        logger.info(f"ì „ì²˜ë¦¬ ëª¨ë“œ: ì ì‘í˜•")
        logger.info(f"ì „ì²˜ë¦¬ ì‚¬ìš© í†µê³„: {total_preset_usage}")
    else:
        logger.info("")
        logger.info(f"ì „ì²˜ë¦¬ ë°©ë²•: {preset}")

    logger.info("="*70)

    return all_results


def test_single_file_comparison():
    """ë‹¨ì¼ íŒŒì¼ë¡œ ì „ì²˜ë¦¬ ë°©ë²• ë¹„êµ í…ŒìŠ¤íŠ¸"""
    pdf_dir = Path("raw_pdf_data")

    # ì²« ë²ˆì§¸ converted íŒŒì¼ ì°¾ê¸°
    for pdf_file in pdf_dir.glob("*.pdf"):
        normalized_name = unicodedata.normalize('NFC', pdf_file.name)
        if 'ë³€í™˜' in normalized_name or 'converted' in normalized_name:
            compare_preprocessing_methods(pdf_file, dpi=300)
            break


if __name__ == "__main__":
    # ì „ì²´ íŒŒì¼ ì²˜ë¦¬
    main()

    # ë˜ëŠ” ë‹¨ì¼ íŒŒì¼ ë¹„êµ í…ŒìŠ¤íŠ¸
    # test_single_file_comparison()
