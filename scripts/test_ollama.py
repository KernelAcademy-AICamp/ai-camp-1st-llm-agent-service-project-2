#!/usr/bin/env python3
"""
Ollamaë¥¼ ì‚¬ìš©í•œ í•œêµ­ í˜•ì‚¬ë²• AI í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import requests
import json

class KosaulLLM:
    def __init__(self, model_name="kosaul-q4"):
        self.model_name = model_name
        self.base_url = "http://localhost:11434"

    def generate(self, prompt, temperature=0.7):
        """Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "temperature": temperature,
                    "stream": False
                }
            )

            if response.status_code == 200:
                return response.json()["response"]
            else:
                return f"Error: {response.status_code}"

        except requests.exceptions.ConnectionError:
            return "Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤. 'ollama serve'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."

    def chat(self, message, context=None):
        """ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±"""
        try:
            messages = []
            if context:
                messages.append({"role": "system", "content": context})
            messages.append({"role": "user", "content": message})

            response = requests.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model_name,
                    "messages": messages,
                    "stream": False
                }
            )

            if response.status_code == 200:
                return response.json()["message"]["content"]
            else:
                return f"Error: {response.status_code}"

        except requests.exceptions.ConnectionError:
            return "Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤. 'ollama serve'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."

def main():
    # Kosaul Q4 ëª¨ë¸ ì´ˆê¸°í™”
    llm = KosaulLLM("kosaul-q4")

    print("ğŸ›ï¸ í•œêµ­ í˜•ì‚¬ë²• AI ì–´ì‹œìŠ¤í„´íŠ¸ (Q4_K_M)")
    print("-" * 50)

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "í˜•ë²•ìƒ ì •ë‹¹ë°©ìœ„ì˜ ì„±ë¦½ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì‚¬ê¸°ì£„ì™€ íš¡ë ¹ì£„ì˜ ì°¨ì´ì ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ìŒì£¼ìš´ì „ì˜ ì²˜ë²Œ ê¸°ì¤€ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]

    for i, question in enumerate(test_questions, 1):
        print(f"\nì§ˆë¬¸ {i}: {question}")
        print("ë‹µë³€:", llm.generate(question))
        print("-" * 50)

    # ëŒ€í™”í˜• ëª¨ë“œ
    print("\nğŸ’¬ ëŒ€í™” ëª¨ë“œ (ì¢…ë£Œ: 'quit' ì…ë ¥)")
    while True:
        user_input = input("\nì§ˆë¬¸: ")
        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            break

        response = llm.chat(user_input)
        print("ë‹µë³€:", response)

if __name__ == "__main__":
    main()