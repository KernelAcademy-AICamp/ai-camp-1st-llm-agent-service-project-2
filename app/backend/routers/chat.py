"""
Chat & Search Router
ì±—ë´‡ ë° ê²€ìƒ‰ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api", tags=["chat"])


class ChatRequest(BaseModel):
    message: str
    context: Optional[str] = None
    temperature: Optional[float] = 0.7


class ChatResponse(BaseModel):
    response: str
    timestamp: str
    model: str


class SearchRequest(BaseModel):
    query: str
    filters: Optional[Dict[str, Any]] = None
    limit: Optional[int] = 10


class SearchResult(BaseModel):
    id: str
    title: str
    type: str
    summary: str
    date: str
    relevance: float
    citation: Optional[str] = None


class AnalyzeRequest(BaseModel):
    content: str
    document_type: Optional[str] = None


class AnalyzeResponse(BaseModel):
    analysis: str
    sources: List[Dict[str, Any]]
    timestamp: str


def setup_chat_routes(
    constitutional_chatbot,
    llm_client,
    hybrid_retriever
):
    """ì±—ë´‡ ë° ê²€ìƒ‰ ë¼ìš°íŠ¸ ì„¤ì •"""

    @router.post("/chat", response_model=ChatResponse)
    async def chat(request: ChatRequest):
        """Constitutional AI ê¸°ë°˜ ë²•ë¥  ì±—ë´‡"""
        if constitutional_chatbot:
            try:
                result = constitutional_chatbot.chat(
                    query=request.message,
                    top_k=5,
                    include_critique_log=False
                )

                response_text = result['answer']
                if result.get('sources'):
                    response_text += "\n\nğŸ“š ì°¸ê³  ìë£Œ:\n"
                    for i, source in enumerate(result['sources'][:3], 1):
                        metadata = source.get('metadata', {})
                        response_text += f"{i}. {metadata.get('source', 'Unknown')} - {metadata.get('date', '')}\n"

                return ChatResponse(
                    response=response_text,
                    timestamp=datetime.now().isoformat(),
                    model="GPT-4 + Constitutional AI + RAG"
                )

            except Exception as e:
                logger.error(f"Constitutional AI chat error: {e}")
                if llm_client:
                    response_text = llm_client.generate(
                        prompt=request.message,
                        temperature=request.temperature
                    )
                    return ChatResponse(
                        response=response_text,
                        timestamp=datetime.now().isoformat(),
                        model="GPT-4"
                    )
                raise HTTPException(status_code=500, detail=str(e))

        elif llm_client:
            try:
                response_text = llm_client.generate(
                    prompt=request.message,
                    temperature=request.temperature
                )

                return ChatResponse(
                    response=response_text,
                    timestamp=datetime.now().isoformat(),
                    model="GPT-4"
                )

            except Exception as e:
                logger.error(f"Chat error: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        else:
            raise HTTPException(status_code=503, detail="Chat service not available")

    @router.post("/search", response_model=List[SearchResult])
    async def search_legal_documents(request: SearchRequest):
        """Hybrid Search ê¸°ë°˜ ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰"""
        if hybrid_retriever:
            try:
                results = hybrid_retriever.retrieve(
                    query=request.query,
                    top_k=request.limit or 10,
                    filter_metadata=request.filters
                )

                search_results = []
                for i, result in enumerate(results):
                    metadata = result.get('metadata', {})

                    doc_type = metadata.get('type', 'unknown')
                    if 'íŒë¡€' in metadata.get('source', ''):
                        doc_type = 'case'
                    elif 'ë²•ë ¹' in metadata.get('source', ''):
                        doc_type = 'law'
                    elif 'í•´ì„ë¡€' in metadata.get('source', ''):
                        doc_type = 'interpretation'

                    search_results.append(SearchResult(
                        id=str(i + 1),
                        title=metadata.get('title', f"ë¬¸ì„œ {i + 1}"),
                        type=doc_type,
                        summary=result.get('text', '')[:200],
                        date=metadata.get('date', ''),
                        relevance=min(100, int(result.get('score', 0) * 100)),
                        citation=metadata.get('citation', metadata.get('source', ''))
                    ))

                logger.info(f"Search returned {len(search_results)} results for query: {request.query}")
                return search_results

            except Exception as e:
                logger.error(f"Search error: {e}")
                return _get_mock_search_results(request.query, request.limit)
        else:
            return _get_mock_search_results(request.query, request.limit)

    @router.post("/analyze", response_model=AnalyzeResponse)
    async def analyze_document(request: AnalyzeRequest):
        """ë²•ë¥  ë¬¸ì„œ ë¶„ì„ (Constitutional AI ì ìš©)"""
        if constitutional_chatbot:
            try:
                analysis_query = f"""ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ë²•ì  ìŸì ì„ íŒŒì•…í•´ì£¼ì„¸ìš”:

{request.content}

ë¶„ì„ í˜•ì‹:
1. ë¬¸ì„œ ìš”ì•½
2. ì£¼ìš” ë²•ì  ìŸì 
3. ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€
4. ì‹¤ë¬´ì  ì‹œì‚¬ì """

                result = constitutional_chatbot.chat(
                    query=analysis_query,
                    top_k=5,
                    include_critique_log=False
                )

                return AnalyzeResponse(
                    analysis=result['answer'],
                    sources=result.get('sources', []),
                    timestamp=datetime.now().isoformat()
                )

            except Exception as e:
                logger.error(f"Constitutional AI analysis error: {e}")
                if llm_client:
                    analysis_text = llm_client.generate(
                        prompt=analysis_query,
                        temperature=0.1
                    )
                    return AnalyzeResponse(
                        analysis=analysis_text,
                        sources=[],
                        timestamp=datetime.now().isoformat()
                    )
                raise HTTPException(status_code=500, detail=str(e))

        elif llm_client:
            try:
                prompt = f"""ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ë²•ì  ìŸì ì„ íŒŒì•…í•´ì£¼ì„¸ìš”:

{request.content}

ë¶„ì„ í˜•ì‹:
1. ë¬¸ì„œ ìš”ì•½
2. ì£¼ìš” ë²•ì  ìŸì 
3. ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€
4. ì‹¤ë¬´ì  ì‹œì‚¬ì """

                analysis_text = llm_client.generate(
                    prompt=prompt,
                    temperature=0.1
                )

                return AnalyzeResponse(
                    analysis=analysis_text,
                    sources=[],
                    timestamp=datetime.now().isoformat()
                )

            except Exception as e:
                logger.error(f"Document analysis error: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        else:
            raise HTTPException(status_code=503, detail="Analysis service not available")

    return router


def _get_mock_search_results(query: str, limit: int) -> List[SearchResult]:
    """Mock ê²€ìƒ‰ ê²°ê³¼ (Fallback)"""
    mock_results = [
        SearchResult(
            id="1",
            title="ëŒ€ë²•ì› 2023ë„1234 íŒê²°",
            type="case",
            summary="ìœ„ë²•ìˆ˜ì§‘ì¦ê±°ì˜ ì¦ê±°ëŠ¥ë ¥ì— ê´€í•œ íŒë‹¨ ê¸°ì¤€ì„ ì œì‹œí•œ ì‚¬ë¡€",
            date="2023-12-15",
            relevance=95.0,
            citation="ëŒ€ë²•ì› 2023. 12. 15. ì„ ê³  2023ë„1234 íŒê²°"
        ),
        SearchResult(
            id="2",
            title="í˜•ì‚¬ì†Œì†¡ë²• ì œ308ì¡°ì˜2",
            type="law",
            summary="ìœ„ë²•ìˆ˜ì§‘ì¦ê±°ì˜ ë°°ì œ - ì ë²•í•œ ì ˆì°¨ì— ë”°ë¥´ì§€ ì•„ë‹ˆí•˜ê³  ìˆ˜ì§‘í•œ ì¦ê±°ëŠ” ì¦ê±°ë¡œ í•  ìˆ˜ ì—†ë‹¤",
            date="2007-06-01",
            relevance=90.0,
            citation="í˜•ì‚¬ì†Œì†¡ë²• ì œ308ì¡°ì˜2"
        )
    ]
    return mock_results[:limit]
